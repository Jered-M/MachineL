#!/usr/bin/env python3
"""
DÃ©ploiement du modÃ¨le face.h5 sur l'application React Native
CrÃ©e les fichiers TensorFlow.js manualmente
"""

import tensorflow as tf
import json
import numpy as np
from pathlib import Path

print("=" * 70)
print("ğŸš€ DÃ‰PLOIEMENT DU MODÃˆLE face.h5 SUR L'APPLICATION")
print("=" * 70)
print()

try:
    # Charger le modÃ¨le H5
    print("ğŸ“¥ Chargement du modÃ¨le face.h5...")
    model_path = Path('api/face.h5')
    model = tf.keras.models.load_model(model_path)
    print("âœ… ModÃ¨le chargÃ©")
    print()
    
    # Info du modÃ¨le
    print("ğŸ“Š Informations du modÃ¨le:")
    print(f"   Input shape: {model.input_shape}")
    print(f"   Output shape: {model.output_shape}")
    print(f"   Couches: {len(model.layers)}")
    print(f"   ParamÃ¨tres: {model.count_params():,}")
    print()
    
    # CrÃ©er le rÃ©pertoire de sortie
    output_dir = Path("assets/models")
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ RÃ©pertoire: {output_dir}")
    print()
    
    # Obtenir la configuration du modÃ¨le
    print("ğŸ”„ Extraction de la configuration du modÃ¨le...")
    model_config = model.get_config()
    print("âœ… Configuration extraite")
    print()
    
    # CrÃ©er le fichier model.json
    print("ğŸ“ CrÃ©ation de model.json...")
    
    model_json = {
        "format": "layers-model",
        "generatedBy": "TensorFlow.js Converter",
        "convertedBy": "face-recognition-deployment",
        "modelTopology": model_config,
        "weightsManifest": [
            {
                "paths": ["model.weights.bin"],
                "weights": []
            }
        ]
    }
    
    # Sauvegarder model.json
    json_path = output_dir / "model.json"
    with open(json_path, "w") as f:
        json.dump(model_json, f, indent=2)
    
    json_size_kb = json_path.stat().st_size / 1024
    print(f"âœ… model.json crÃ©Ã© ({json_size_kb:.2f} KB)")
    print()
    
    # CrÃ©er le fichier model.weights.bin
    print("ğŸ“ CrÃ©ation de model.weights.bin...")
    
    # Obtenir tous les poids
    weights = model.get_weights()
    
    # Concatener tous les poids en bytes
    weights_bytes = b""
    for w in weights:
        # Convertir en float32 et en bytes
        w_float32 = w.astype(np.float32)
        weights_bytes += w_float32.tobytes()
    
    # Sauvegarder
    bin_path = output_dir / "model.weights.bin"
    with open(bin_path, "wb") as f:
        f.write(weights_bytes)
    
    bin_size_mb = bin_path.stat().st_size / (1024 * 1024)
    print(f"âœ… model.weights.bin crÃ©Ã© ({bin_size_mb:.2f} MB)")
    print()
    
    # VÃ©rifier les fichiers
    print("âœ… VÃ©rification des fichiers...")
    print()
    
    files_ok = True
    for file in [json_path, bin_path]:
        if file.exists():
            size = file.stat().st_size
            if size > 0:
                print(f"   âœ… {file.name} ({size:,} bytes)")
            else:
                print(f"   âŒ {file.name} VIDE!")
                files_ok = False
        else:
            print(f"   âŒ {file.name} NON TROUVÃ‰!")
            files_ok = False
    
    print()
    
    if not files_ok:
        print("âŒ Erreur: Fichiers incomplets!")
        exit(1)
    
    print("=" * 70)
    print("âœ… DÃ‰PLOIEMENT RÃ‰USSI!")
    print("=" * 70)
    print()
    print(f"ğŸ“ Fichiers crÃ©Ã©s dans: {output_dir}/")
    print()
    print("âœ… Le modÃ¨le est prÃªt pour l'application!")
    print()
    print("ğŸ“ Prochaines Ã©tapes:")
    print("   1. ExÃ©cutez: npm install")
    print("   2. ExÃ©cutez: npm run android (ou ios/web)")
    print("   3. Testez la reconnaissance faciale")
    print()
    
except Exception as e:
    print(f"âŒ Erreur: {e}")
    import traceback
    traceback.print_exc()
    exit(1)
